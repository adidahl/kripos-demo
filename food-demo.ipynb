{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food Image Classification Demo\n",
    "\n",
    "This notebook demonstrates how to build a simple food classifier using transfer learning, storing data in MinIO, and tracking experiments with MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda create -n food-demo python=3.11 -y\n",
    "!conda activate food-demo\n",
    "!pip install --user tensorflow keras pillow boto3 mlflow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Up MinIO Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import site\n",
    "import os\n",
    "\n",
    "# Add user site-packages to path\n",
    "user_site = site.getusersitepackages()\n",
    "if user_site not in sys.path:\n",
    "    sys.path.append(user_site)\n",
    "\n",
    "# Check the paths Python is searching\n",
    "print(f\"Python is looking for modules in these directories: {sys.path}\")\n",
    "\n",
    "# Now try importing boto3\n",
    "import boto3\n",
    "print(f\"Successfully imported boto3 version: {boto3.__version__}\")\n",
    "from botocore.client import Config\n",
    "\n",
    "# Create a MinIO client\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url='http://minio:9000',\n",
    "    aws_access_key_id='minioadmin',\n",
    "    aws_secret_access_key='minioadmin',\n",
    "    config=Config(signature_version='s3v4'),\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "# Create a bucket for food images\n",
    "bucket_name = 'food-images'\n",
    "try:\n",
    "    s3_client.create_bucket(Bucket=bucket_name)\n",
    "    print(f\"Bucket '{bucket_name}' created successfully\")\n",
    "except s3_client.exceptions.BucketAlreadyOwnedByYou:\n",
    "    print(f\"Bucket '{bucket_name}' already exists\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating bucket: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Food Images Dataset\n",
    "\n",
    "We'll use a subset of the Food-101 dataset, focusing on just 3 categories for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import time\n",
    "\n",
    "# Create directories for each class\n",
    "os.makedirs('/tmp/food-data', exist_ok=True)\n",
    "classes = ['pizza', 'sushi', 'hamburger']\n",
    "\n",
    "for food_class in classes:\n",
    "    class_dir = f'/tmp/food-data/{food_class}'\n",
    "    os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "# Sample image URLs for each class - these are stable image URLs for demonstration\n",
    "image_urls = {\n",
    "    'pizza': [\n",
    "        'https://upload.wikimedia.org/wikipedia/commons/a/a3/Eq_it-na_pizza-margherita_sep2005_sml.jpg',\n",
    "        'https://www.bora.com/fileadmin/website_content/Rezepte/X_BO_Rezepte/X_BO_Automatikrezepte/Pizza.jpg',\n",
    "        'https://www.zauberdergewuerze.de/magazin/wp-content/uploads/2023/03/05_oregano_istock-1174701047.jpg',\n",
    "        'https://hero-pizza.vercel.app/static/media/pizza2.7f95f4bae3bf65fb9fe6.jpeg',\n",
    "        'https://assets.tmecosys.com/image/upload/t_web_rdp_recipe_584x480_1_5x/img/recipe/ras/Assets/ecaeb2cc-a950-4645-a648-9137305b3287/Derivates/df977b90-193d-49d4-a59d-8dd922bcbf65.jpg'\n",
    "    ],\n",
    "    'sushi': [\n",
    "        'https://assets.tmecosys.com/image/upload/t_web_rdp_recipe_584x480_1_5x/img/recipe/ras/Assets/64EF898D-2EDD-4B47-A456-E6A7D137AC91/Derivates/00f76cac-64f6-4573-be4f-e604a7d99143.jpg',\n",
    "        'https://images.lecker.de/sushi-selber-machen-b3jpg,id=48df8ccb,b=lecker,w=1200,rm=sk.jpeg',\n",
    "        'https://www.kindernetz.de/sendungen/schmecksplosion/1712332657170%2Cimage-knet-4154~_v-1x1@2dL_-029cdd853d61a51824ed2ee643deeae504b065c1.jpg',\n",
    "        'https://www.justonecookbook.com/wp-content/uploads/2020/01/Sushi-Rolls-Maki-Sushi-â€“-Hosomaki-1106-II.jpg',\n",
    "        'https://www.spoton.com/blog/content/images/size/w1200/2024/09/1.-what-is-maki-sushi-guide-thin-rolls-hand-roll-shrimp-tempura-tuna-salmon-rice.jpeg'\n",
    "    ],\n",
    "    'hamburger': [\n",
    "        'https://assets.epicurious.com/photos/5c745a108918ee7ab68daf79/1:1/w_2560%2Cc_limit/Smashburger-recipe-120219.jpg',\n",
    "        'https://www.allrecipes.com/thmb/vpth8WDEhejGg_pD7dQgWZVbjyQ=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc()/8667932-garlic-butter-burger-01-4x3-ccd6c1f3548b4aab83ae65dd4221bc7c.jpg',\n",
    "        'https://www.southernliving.com/thmb/DChRkqQRlsAwsn5La1ZLprzJSzQ=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc():focal(3073x1792:3075x1794)/ultimate-southern-burger_batch64_beauty01-86-b9c26e256dd34e39b6c0cfb0c02a9fef.jpg',\n",
    "        'https://www.gilde.no/assets/images/_heroimage/umami-burger.jpg',\n",
    "        'https://www.v-kitchen.ch/recipe/2382e534-f65b-4669-a5f4-8fc4731ebe45.jpg'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Download images for each class\n",
    "for food_class, urls in image_urls.items():\n",
    "    print(f\"Downloading {food_class} images...\")\n",
    "    \n",
    "    for i, url in enumerate(urls):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                # Check if it's a valid image\n",
    "                img = Image.open(BytesIO(response.content))\n",
    "                img_path = f\"/tmp/food-data/{food_class}/{i+1}.jpg\"\n",
    "                img.save(img_path)\n",
    "                print(f\"  - Saved {img_path}\")\n",
    "            else:\n",
    "                print(f\"  - Failed to download image {i+1} for {food_class}: HTTP {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - Error downloading image {i+1} for {food_class}: {e}\")\n",
    "        \n",
    "        # Pause to avoid rate limiting\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Create training and validation folders\n",
    "    os.makedirs(f'/tmp/train/{food_class}', exist_ok=True)\n",
    "    os.makedirs(f'/tmp/val/{food_class}', exist_ok=True)\n",
    "    \n",
    "    print(f\"Downloaded {len(urls)} images for {food_class}\")\n",
    "\n",
    "print(\"Image download complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Manual Upload\n",
    "\n",
    "If automatic download doesn't work, you can upload images manually by running these commands in the container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for each class\n",
    "for food_class in classes:\n",
    "    os.makedirs(f'/tmp/food-data/{food_class}', exist_ok=True)\n",
    "    \n",
    "print(\"For a real demo, you can upload images directly to these directories:\")\n",
    "for food_class in classes:\n",
    "    print(f\"/tmp/food-data/{food_class}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Upload Images to MinIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Upload the images to MinIO\n",
    "for food_class in classes:\n",
    "    images = glob.glob(f'/tmp/food-data/{food_class}/**/*.jpg', recursive=True)\n",
    "    images += glob.glob(f'/tmp/food-data/{food_class}/**/*.jpeg', recursive=True)\n",
    "    images += glob.glob(f'/tmp/food-data/{food_class}/**/*.png', recursive=True)\n",
    "    \n",
    "    print(f\"Found {len(images)} images for {food_class}\")\n",
    "    \n",
    "    for idx, image_path in enumerate(images):\n",
    "        image_name = os.path.basename(image_path)\n",
    "        s3_key = f'{food_class}/{image_name}'\n",
    "        \n",
    "        try:\n",
    "            s3_client.upload_file(image_path, bucket_name, s3_key)\n",
    "            if idx % 10 == 0 and idx > 0:\n",
    "                print(f\"Uploaded {idx} {food_class} images to MinIO\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading {image_path}: {e}\")\n",
    "    \n",
    "    print(f\"Completed uploading {food_class} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Training and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "# Create train and validation directories\n",
    "train_dir = '/tmp/train'\n",
    "val_dir = '/tmp/val'\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# Download images from MinIO for training\n",
    "for food_class in classes:\n",
    "    os.makedirs(f'{train_dir}/{food_class}', exist_ok=True)\n",
    "    os.makedirs(f'{val_dir}/{food_class}', exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # List objects in the bucket for this class\n",
    "        response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=f'{food_class}/')\n",
    "        \n",
    "        if 'Contents' not in response:\n",
    "            print(f\"No images found for {food_class} in MinIO\")\n",
    "            continue\n",
    "            \n",
    "        objects = response['Contents']\n",
    "        print(f\"Found {len(objects)} objects for {food_class}\")\n",
    "        \n",
    "        # Split images 80/20 for training/validation\n",
    "        total_images = len(objects)\n",
    "        train_count = int(total_images * 0.8)\n",
    "        \n",
    "        for idx, obj in enumerate(objects):\n",
    "            key = obj['Key']\n",
    "            filename = os.path.basename(key)\n",
    "            \n",
    "            # Skip directory entries or non-image files\n",
    "            if not filename or not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                continue\n",
    "                \n",
    "            # Determine if this goes to train or validation\n",
    "            if idx < train_count:\n",
    "                local_path = f'{train_dir}/{food_class}/{filename}'\n",
    "            else:\n",
    "                local_path = f'{val_dir}/{food_class}/{filename}'\n",
    "                \n",
    "            # Download the image\n",
    "            s3_client.download_file(bucket_name, key, local_path)\n",
    "            \n",
    "            if idx % 10 == 0 and idx > 0:\n",
    "                print(f\"Downloaded {idx} images for {food_class}\")\n",
    "        \n",
    "        print(f\"Completed downloading {food_class} images for training and validation\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {food_class}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build and Train the Model with MLflow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Set up MLflow tracking\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "mlflow.set_experiment(\"food-classification\")\n",
    "\n",
    "# Verify training data\n",
    "for food_class in classes:\n",
    "    train_images = glob.glob(f'{train_dir}/{food_class}/*')\n",
    "    val_images = glob.glob(f'{val_dir}/{food_class}/*')\n",
    "    print(f\"{food_class}: {len(train_images)} training images, {len(val_images)} validation images\")\n",
    "\n",
    "# Set up data generators with augmentation for training\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model using transfer learning with MobileNetV2\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(len(classes), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure MLflow to use MinIO for artifacts\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "# Configure MLflow to use MinIO for artifacts\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://minio:9000\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minioadmin\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minioadmin\"\n",
    "\n",
    "# Set up tracking server and experiment\n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "mlflow.set_experiment(\"food-classification-s3\")\n",
    "\n",
    "# Create MinIO bucket for MLflow artifacts if it doesn't exist\n",
    "import boto3\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url='http://minio:9000',\n",
    "    aws_access_key_id='minioadmin',\n",
    "    aws_secret_access_key='minioadmin'\n",
    ")\n",
    "\n",
    "mlflow_bucket = \"mlflow-artifacts\"\n",
    "try:\n",
    "    s3_client.create_bucket(Bucket=mlflow_bucket)\n",
    "    print(f\"Created bucket '{mlflow_bucket}' for MLflow artifacts\")\n",
    "except Exception as e:\n",
    "    print(f\"Bucket '{mlflow_bucket}' might already exist: {e}\")\n",
    "\n",
    "# Start MLflow run with S3 artifacts\n",
    "with mlflow.start_run() as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"MobileNetV2\")\n",
    "    mlflow.log_param(\"img_height\", img_height)\n",
    "    mlflow.log_param(\"img_width\", img_width)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"classes\", classes)\n",
    "    mlflow.log_param(\"epochs\", 5)\n",
    "    \n",
    "    # For metrics that we already have from previous training:\n",
    "    for epoch in range(len(history.history['accuracy'])):\n",
    "        mlflow.log_metric(\"train_accuracy\", history.history['accuracy'][epoch], step=epoch)\n",
    "        mlflow.log_metric(\"train_loss\", history.history['loss'][epoch], step=epoch)\n",
    "        mlflow.log_metric(\"val_accuracy\", history.history['val_accuracy'][epoch], step=epoch)\n",
    "        mlflow.log_metric(\"val_loss\", history.history['val_loss'][epoch], step=epoch)\n",
    "    \n",
    "    # Try to log model with MinIO as backend\n",
    "    try:\n",
    "        # Create a sample input for model signature\n",
    "        import numpy as np\n",
    "        sample_input = np.zeros((1, img_height, img_width, 3), dtype=np.float32)\n",
    "        \n",
    "        # Log model to MinIO\n",
    "        artifact_path = \"s3://{}/{}\".format(mlflow_bucket, run.info.run_id)\n",
    "        mlflow.keras.log_model(\n",
    "            model, \n",
    "            \"keras_model\",\n",
    "            artifact_path=artifact_path,\n",
    "            signature=mlflow.models.infer_signature(sample_input, model.predict(sample_input))\n",
    "        )\n",
    "        print(f\"Model saved to artifact store at {artifact_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not save model to artifact store: {e}\")\n",
    "        # Fall back to saving in MinIO directly\n",
    "        model_path = '/tmp/food_classifier_model.h5'\n",
    "        model.save(model_path)\n",
    "        s3_client.upload_file(model_path, bucket_name, 'models/food_classifier_model.h5')\n",
    "        print(f\"Model saved directly to MinIO: {bucket_name}/models/food_classifier_model.h5\")\n",
    "    \n",
    "    run_id = run.info.run_id\n",
    "    print(f\"MLflow run logged with S3 artifacts. Run ID: {run_id}\")\n",
    "    print(f\"View in MLflow UI: http://localhost:5001/#/experiments/0/runs/{run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test the Model with New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to predict food class\n",
    "def predict_food(image_path):\n",
    "    img = image.load_img(image_path, target_size=(img_height, img_width))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    \n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = classes[np.argmax(predictions[0])]\n",
    "    confidence = np.max(predictions[0])\n",
    "    \n",
    "    # Create a dict of all class predictions for visualization\n",
    "    all_predictions = {classes[i]: float(predictions[0][i]) for i in range(len(classes))}\n",
    "    \n",
    "    return predicted_class, confidence, all_predictions\n",
    "\n",
    "# Test with validation images\n",
    "test_images = []\n",
    "for food_class in classes:\n",
    "    # Get up to 2 test images from each class in validation set\n",
    "    class_images = glob.glob(f'{val_dir}/{food_class}/*')[:2]\n",
    "    test_images.extend(class_images)\n",
    "\n",
    "# If no validation images found, try with training images\n",
    "if not test_images:\n",
    "    for food_class in classes:\n",
    "        class_images = glob.glob(f'{train_dir}/{food_class}/*')[:2]\n",
    "        test_images.extend(class_images)\n",
    "\n",
    "# Display and predict test images\n",
    "for test_image in test_images:\n",
    "    # Make prediction\n",
    "    predicted_class, confidence, all_predictions = predict_food(test_image)\n",
    "    \n",
    "    # Display image and prediction\n",
    "    img = image.load_img(test_image)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Prediction: {predicted_class} ({confidence:.2f})\\nTrue class: {os.path.basename(os.path.dirname(test_image))}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Show prediction breakdown\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    plt.barh(list(all_predictions.keys()), list(all_predictions.values()))\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.title('Class Predictions')\n",
    "    plt.xlim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Image: {test_image}\")\n",
    "    print(f\"Prediction: {predicted_class} with {confidence:.2f} confidence\")\n",
    "    print(f\"True class: {os.path.basename(os.path.dirname(test_image))}\")\n",
    "    print(\"All predictions:\", all_predictions)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load Model from MLflow and Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.keras\n",
    "import boto3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "# Set up environment variables for MLflow to connect to MinIO\n",
    "import os\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://minio:9000\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minioadmin\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minioadmin\"\n",
    "\n",
    "# Check if your model exists in MLflow \n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "\n",
    "# Find your latest run\n",
    "latest_runs = mlflow.search_runs(experiment_ids=[\"0\"], max_results=1, order_by=[\"start_time DESC\"])\n",
    "if len(latest_runs) > 0:\n",
    "    run_id = latest_runs.iloc[0].run_id\n",
    "    print(f\"Found latest run: {run_id}\")\n",
    "else:\n",
    "    run_id = \"paste_your_run_id_here\"  # Fallback to manual input\n",
    "    print(f\"Using manually specified run ID: {run_id}\")\n",
    "\n",
    "# Try to load the model from MLflow with S3 artifact store\n",
    "try:\n",
    "    # First try with the \"model\" artifact path\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "    loaded_model = mlflow.keras.load_model(model_uri)\n",
    "    print(f\"Model loaded successfully from MLflow: {model_uri}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model from path 'model': {e}\")\n",
    "    try:\n",
    "        # If that fails, try with \"keras_model\" path instead\n",
    "        model_uri = f\"runs:/{run_id}/keras_model\"\n",
    "        loaded_model = mlflow.keras.load_model(model_uri)\n",
    "        print(f\"Model loaded successfully from MLflow: {model_uri}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model from path 'keras_model': {e}\")\n",
    "        print(\"Falling back to model in memory or loading from MinIO directly\")\n",
    "        \n",
    "        # As a fallback, try to load the model from MinIO directly\n",
    "        try:\n",
    "            # Create a MinIO client\n",
    "            s3_client = boto3.client(\n",
    "                's3',\n",
    "                endpoint_url='http://minio:9000',\n",
    "                aws_access_key_id='minioadmin',\n",
    "                aws_secret_access_key='minioadmin'\n",
    "            )\n",
    "            \n",
    "            # Download model from MinIO\n",
    "            bucket_name = 'food-images'  # Use your bucket name\n",
    "            model_path = '/tmp/food_classifier_model.h5'\n",
    "            s3_client.download_file(bucket_name, 'models/food_classifier_model.h5', model_path)\n",
    "            \n",
    "            # Load model from downloaded file\n",
    "            from tensorflow.keras.models import load_model\n",
    "            loaded_model = load_model(model_path)\n",
    "            print(f\"Model loaded from MinIO: {bucket_name}/models/food_classifier_model.h5\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model from MinIO: {e}\")\n",
    "            print(\"Using the model from memory instead\")\n",
    "            loaded_model = model  # Fallback to model in memory\n",
    "\n",
    "# Create a prediction function\n",
    "def predict_image(image_path):\n",
    "    # Preprocess the image\n",
    "    img = image.load_img(image_path, target_size=(img_height, img_width))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = loaded_model.predict(img_array)\n",
    "    predicted_class = classes[np.argmax(predictions[0])]\n",
    "    confidence = float(np.max(predictions[0]))\n",
    "    \n",
    "    return {\n",
    "        \"class\": predicted_class,\n",
    "        \"confidence\": confidence,\n",
    "        \"all_predictions\": {classes[i]: float(predictions[0][i]) for i in range(len(classes))}\n",
    "    }\n",
    "\n",
    "# Test the prediction function with a test image\n",
    "if test_images:\n",
    "    result = predict_image(test_images[0])\n",
    "    print(f\"Prediction using loaded model: {result['class']} with {result['confidence']:.2f} confidence\")\n",
    "    print(f\"All predictions: {result['all_predictions']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
